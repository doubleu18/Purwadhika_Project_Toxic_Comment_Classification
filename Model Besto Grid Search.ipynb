{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('trainMaster.csv')\n",
    "final = pd.read_csv('dfTestDataLabelFinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 15 columns):\n",
      "Unnamed: 0       159571 non-null int64\n",
      "id               159571 non-null object\n",
      "comment_text     159571 non-null object\n",
      "toxic            159571 non-null int64\n",
      "severe_toxic     159571 non-null int64\n",
      "obscene          159571 non-null int64\n",
      "threat           159571 non-null int64\n",
      "insult           159571 non-null int64\n",
      "identity_hate    159571 non-null int64\n",
      "toxic_level      159571 non-null int64\n",
      "clean            159571 non-null int64\n",
      "length           159571 non-null int64\n",
      "word_count       159571 non-null int64\n",
      "polarity         159571 non-null float64\n",
      "subjectivity     159571 non-null float64\n",
      "dtypes: float64(2), int64(11), object(2)\n",
      "memory usage: 18.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63978 entries, 0 to 63977\n",
      "Data columns (total 14 columns):\n",
      "id               63978 non-null object\n",
      "comment_text     63978 non-null object\n",
      "toxic            63978 non-null int64\n",
      "severe_toxic     63978 non-null int64\n",
      "obscene          63978 non-null int64\n",
      "threat           63978 non-null int64\n",
      "insult           63978 non-null int64\n",
      "identity_hate    63978 non-null int64\n",
      "toxic_level      63978 non-null int64\n",
      "clean            63978 non-null int64\n",
      "length           63978 non-null int64\n",
      "word_count       63978 non-null int64\n",
      "polarity         63978 non-null float64\n",
      "subjectivity     63978 non-null float64\n",
      "dtypes: float64(2), int64(10), object(2)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ReviewText):\n",
    "    ReviewText = ReviewText.str.replace(\"(<br/>)\", \"\")\n",
    "    ReviewText = ReviewText.str.replace('(<a).*(>).*(</a>)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&amp)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&gt)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&lt)', '')\n",
    "    ReviewText = ReviewText.str.replace('(\\xa0)', ' ')\n",
    "    ReviewText = ReviewText.str.replace('(\\n)', ' ') \n",
    "    ReviewText = ReviewText.str.replace('==', ' ') \n",
    "    return ReviewText\n",
    "\n",
    "train['comment_text'] = preprocess(train['comment_text'])\n",
    "final['comment_text'] = preprocess(final['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train['comment_text']\n",
    "\n",
    "categories = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = train_test_split(train, random_state=42, test_size=0.30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OwO\n"
     ]
    }
   ],
   "source": [
    "# print('OwO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 5\n",
    "# kf = KFold(n_splits=K, shuffle=True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dFold = {}\n",
    "# for i in range(1,8):\n",
    "#     dFold['Hasilfold{}'.format(i)] = kf.split(x,datay[i-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, matthews_corrcoef, f1_score, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzer for Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = []\n",
    "for words in stopwords.words('english'):\n",
    "    s = [char for char in words if char not in string.punctuation]\n",
    "    stop.append(''.join(s))\n",
    "stop.extend(['may','also','across','among','beside','however','yet','within'])\n",
    "\n",
    "# stemmer = SnowballStemmer(\"english\")\n",
    "# def stemming(sentence):\n",
    "#     stemSentence = \"\"\n",
    "#     for word in sentence.split():\n",
    "#         stem = stemmer.stem(word)\n",
    "#         stemSentence += stem\n",
    "#         stemSentence += \" \"\n",
    "#     stemSentence = stemSentence.strip()\n",
    "#     return stemSentence\n",
    "\n",
    "def process_normal(text):\n",
    "    return [word for word in text.split() if word.lower() not in stop]\n",
    "\n",
    "def process_nocase(text):\n",
    "    return [word.lower() for word in text.split() if word.lower() not in stop]\n",
    "\n",
    "def process_nopunc(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stop]\n",
    "\n",
    "def process_nocasepunc(text):\n",
    "    nocasepunc = [char for char in text if char not in string.punctuation]\n",
    "    nocasepunc = ''.join(nocasepunc)\n",
    "    return [word.lower() for word in nocasepunc.split() if word.lower() not in stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,3), stop_words='english', max_features=30000)\n",
    "# vectorizer = TfidfVectorizer(, analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "#     norm = ('l1','l2','none')\n",
    "#     max_features  = (10000,50000,100000,150000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_pipeline = Pipeline([\n",
    "#             ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=30000)),\n",
    "            ('classifier', LogisticRegression()),\n",
    "        ])\n",
    "\n",
    "def pipeline_model_training(category, dataTrain, targetTrain):\n",
    "    # Training logistic regression model on train data\n",
    "    return LogReg_pipeline.fit(dataTrain, targetTrain)\n",
    "\n",
    "def pipeline_predict(category, dictPred, dictPredProba, dictHasil, dataTest, targetTest):\n",
    "    # calculating test accuracy\n",
    "    prediction = LogReg_pipeline.predict(dataTest)\n",
    "    dictPredProba['{}'.format(category)] = LogReg_pipeline.predict_proba(dataTest)\n",
    "    dictPred[category] = prediction \n",
    "    dictHasil['{}_accuracy'.format(category)] = accuracy_score(targetTest, prediction)\n",
    "    dictHasil['{}_f1score'.format(category)] = f1_score(targetTest, prediction, average = 'macro')\n",
    "    dictHasil['{}_logloss'.format(category)] = log_loss(targetTest, dictPredProba[category])\n",
    "    dictHasil['{}_rocauc'.format(category)] = roc_auc_score(targetTest, dictPredProba[category][:,1])\n",
    "    dictHasil['{}_matthews_corrcoef'.format(category)] = matthews_corrcoef(targetTest, prediction)\n",
    "    dictHasil['{}_classification_report'.format(category)] = classification_report(targetTest, prediction)\n",
    "    dictHasil['{}_confusion_matrix'.format(category)] = classification_report(targetTest, prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OwO\n"
     ]
    }
   ],
   "source": [
    "print('OwO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for category in categories:\n",
    "#     norm = ('l1','l2','none')\n",
    "#     max_features  = (10000,50000,100000,150000)\n",
    "\n",
    "\n",
    "#     param_grid = {'norm': norm, 'max_features':max_features, }\n",
    "\n",
    "#     gs = GridSearchCV(LogReg_pipeline.steps[0][1],param_grid,scoring='accuracy')\n",
    "\n",
    "\n",
    "#     gs = gs.fit(x_train, y_train[category])\n",
    "    \n",
    "#     print(category)\n",
    "#     print(gs.best_score_)\n",
    "#     print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(train['comment_text'])\n",
    "\n",
    "x_train = vectorizer.transform(train['comment_text'])\n",
    "y_train = train.drop(labels = ['id','comment_text'], axis=1)\n",
    "x_test = vectorizer.transform(test['comment_text'])\n",
    "y_test = test.drop(labels = ['id','comment_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dPredict_train = {}\n",
    "dPredictProba_train = {}\n",
    "dResult_train = {}\n",
    "\n",
    "for category in categories:\n",
    "    pipeline_model_training(category, x_train, y_train[category])\n",
    "    pipeline_predict(category, dPredict_train, dPredictProba_train, dResult_train, x_train, y_train[category])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bikin_report(hasil, namadf, namacol):\n",
    "    listItem = []\n",
    "\n",
    "    for category in categories:\n",
    "        listItem.append([category,\n",
    "                        hasil['{}_accuracy'.format(category)],\n",
    "                        hasil['{}_f1score'.format(category)],\n",
    "                        hasil['{}_logloss'.format(category)],\n",
    "                        hasil['{}_rocauc'.format(category)],\n",
    "                        hasil['{}_matthews_corrcoef'.format(category)],\n",
    "                        ])\n",
    "\n",
    "    namadf = pd.DataFrame(columns=['Category','{} Acc'.format(namacol), '{} F1 Score'.format(namacol),'{} Log Loss'.format(namacol),'{} ROC AUC'.format(namacol),'{} Matthew Corr Coef'.format(namacol),],\n",
    "                         data=listItem)\n",
    "    return namadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Train F1 Score</th>\n",
       "      <th>Train Log Loss</th>\n",
       "      <th>Train ROC AUC</th>\n",
       "      <th>Train Matthew Corr Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.959561</td>\n",
       "      <td>0.861242</td>\n",
       "      <td>0.107165</td>\n",
       "      <td>0.984151</td>\n",
       "      <td>0.743385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.990752</td>\n",
       "      <td>0.657198</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.991896</td>\n",
       "      <td>0.356164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.979158</td>\n",
       "      <td>0.877397</td>\n",
       "      <td>0.057750</td>\n",
       "      <td>0.992887</td>\n",
       "      <td>0.769900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.997162</td>\n",
       "      <td>0.583279</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.995216</td>\n",
       "      <td>0.276518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.973124</td>\n",
       "      <td>0.823514</td>\n",
       "      <td>0.071457</td>\n",
       "      <td>0.987037</td>\n",
       "      <td>0.668873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.992417</td>\n",
       "      <td>0.643701</td>\n",
       "      <td>0.023826</td>\n",
       "      <td>0.988702</td>\n",
       "      <td>0.372215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category  Train Acc  Train F1 Score  Train Log Loss  Train ROC AUC  \\\n",
       "0          toxic   0.959561        0.861242        0.107165       0.984151   \n",
       "1   severe_toxic   0.990752        0.657198        0.025001       0.991896   \n",
       "2        obscene   0.979158        0.877397        0.057750       0.992887   \n",
       "3         threat   0.997162        0.583279        0.010293       0.995216   \n",
       "4         insult   0.973124        0.823514        0.071457       0.987037   \n",
       "5  identity_hate   0.992417        0.643701        0.023826       0.988702   \n",
       "\n",
       "   Train Matthew Corr Coef  \n",
       "0                 0.743385  \n",
       "1                 0.356164  \n",
       "2                 0.769900  \n",
       "3                 0.276518  \n",
       "4                 0.668873  \n",
       "5                 0.372215  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfReportTrain = bikin_report(dResult_train, 'dfReportTrain', 'Train')\n",
    "dfReportTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Train F1 Score</th>\n",
       "      <th>Train Log Loss</th>\n",
       "      <th>Train ROC AUC</th>\n",
       "      <th>Train Matthew Corr Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.982029</td>\n",
       "      <td>0.741055</td>\n",
       "      <td>0.049249</td>\n",
       "      <td>0.989981</td>\n",
       "      <td>0.531176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.014180</td>\n",
       "      <td>0.127465</td>\n",
       "      <td>0.036528</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.219878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.959561</td>\n",
       "      <td>0.583279</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.984151</td>\n",
       "      <td>0.276518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.974633</td>\n",
       "      <td>0.647075</td>\n",
       "      <td>0.024120</td>\n",
       "      <td>0.987453</td>\n",
       "      <td>0.360177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.984955</td>\n",
       "      <td>0.740356</td>\n",
       "      <td>0.041376</td>\n",
       "      <td>0.990299</td>\n",
       "      <td>0.520544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.992001</td>\n",
       "      <td>0.851810</td>\n",
       "      <td>0.068031</td>\n",
       "      <td>0.992639</td>\n",
       "      <td>0.724757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.997162</td>\n",
       "      <td>0.877397</td>\n",
       "      <td>0.107165</td>\n",
       "      <td>0.995216</td>\n",
       "      <td>0.769900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Train Acc  Train F1 Score  Train Log Loss  Train ROC AUC  \\\n",
       "count   6.000000        6.000000        6.000000       6.000000   \n",
       "mean    0.982029        0.741055        0.049249       0.989981   \n",
       "std     0.014180        0.127465        0.036528       0.004094   \n",
       "min     0.959561        0.583279        0.010293       0.984151   \n",
       "25%     0.974633        0.647075        0.024120       0.987453   \n",
       "50%     0.984955        0.740356        0.041376       0.990299   \n",
       "75%     0.992001        0.851810        0.068031       0.992639   \n",
       "max     0.997162        0.877397        0.107165       0.995216   \n",
       "\n",
       "       Train Matthew Corr Coef  \n",
       "count                 6.000000  \n",
       "mean                  0.531176  \n",
       "std                   0.219878  \n",
       "min                   0.276518  \n",
       "25%                   0.360177  \n",
       "50%                   0.520544  \n",
       "75%                   0.724757  \n",
       "max                   0.769900  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfReportTrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bikin_hasil_pred(hasil, namadf):\n",
    "    listItem = []\n",
    "    \n",
    "    for i in range(len(hasil['toxic'])):\n",
    "        listItem.append([hasil['toxic'][i],\n",
    "                        hasil['severe_toxic'][i],\n",
    "                        hasil['obscene'][i],\n",
    "                        hasil['threat'][i],\n",
    "                        hasil['threat'][i],\n",
    "                        hasil['identity_hate'][i],])\n",
    "        \n",
    "        \n",
    "        if((hasil['toxic'][i] + hasil['severe_toxic'][i] + hasil['obscene'][i] + hasil['threat'][i] + hasil['threat'][i] + hasil['identity_hate'][i]) == 0):\n",
    "            listItem[i].append(1)\n",
    "        else:\n",
    "            listItem[i].append(0)\n",
    "    \n",
    "\n",
    "    namadf = pd.DataFrame(columns=['ToxicPred', 'SToxicPred','ObscenePred','ThreatPred','InsultPred','IdHatePred', 'cleanPred'],\n",
    "                         data=listItem)\n",
    "    return namadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ToxicPred</th>\n",
       "      <th>SToxicPred</th>\n",
       "      <th>ObscenePred</th>\n",
       "      <th>ThreatPred</th>\n",
       "      <th>InsultPred</th>\n",
       "      <th>IdHatePred</th>\n",
       "      <th>cleanPred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ToxicPred  SToxicPred  ObscenePred  ThreatPred  InsultPred  IdHatePred  \\\n",
       "0          0           0            0           0           0           0   \n",
       "1          0           0            0           0           0           0   \n",
       "2          0           0            0           0           0           0   \n",
       "3          0           0            0           0           0           0   \n",
       "4          0           0            0           0           0           0   \n",
       "5          0           0            0           0           0           0   \n",
       "6          0           0            0           0           0           0   \n",
       "7          1           0            1           0           0           0   \n",
       "\n",
       "   cleanPred  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  \n",
       "6          1  \n",
       "7          0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResultTrain = bikin_hasil_pred(dPredict_train, 'dfResultTrain')\n",
    "dfResultTrain.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predict_with_keylabel(namadf, pred, key):\n",
    "    namadf = pd.DataFrame\n",
    "    namadf = pd.concat([pred, key[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'clean']].reset_index(drop=True)], axis=1)\n",
    "    return namadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinalTrain = combine_predict_with_keylabel('dfFinalTrain', dfResultTrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ToxicPred</th>\n",
       "      <th>SToxicPred</th>\n",
       "      <th>ObscenePred</th>\n",
       "      <th>ThreatPred</th>\n",
       "      <th>InsultPred</th>\n",
       "      <th>IdHatePred</th>\n",
       "      <th>cleanPred</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ToxicPred  SToxicPred  ObscenePred  ThreatPred  InsultPred  IdHatePred  \\\n",
       "0          0           0            0           0           0           0   \n",
       "1          0           0            0           0           0           0   \n",
       "2          0           0            0           0           0           0   \n",
       "3          0           0            0           0           0           0   \n",
       "4          0           0            0           0           0           0   \n",
       "\n",
       "   cleanPred  toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0          1      0             0        0       0       0              0   \n",
       "1          1      0             0        0       0       0              0   \n",
       "2          1      0             0        0       0       0              0   \n",
       "3          1      0             0        0       0       0              0   \n",
       "4          1      0             0        0       0       0              0   \n",
       "\n",
       "   clean  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinalTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_dataframe(dfResult):\n",
    "    actCancer = dfResult[dfResult['clean']==0]\n",
    "    actClean = dfResult[dfResult['clean']==1]\n",
    "    \n",
    "    predCancer = dfResult[((dfResult['ToxicPred'] == 1) | (dfResult['SToxicPred'] == 1) | (dfResult['ObscenePred'] == 1)\n",
    "             | (dfResult['ThreatPred'] == 1) | (dfResult['InsultPred'] == 1) | (dfResult['IdHatePred'] == 1))]\n",
    "    \n",
    "    predCancerActCancer = dfResult[((dfResult['ToxicPred'] == dfResult['toxic']) & (dfResult['SToxicPred'] == dfResult['severe_toxic']) & (dfResult['ObscenePred'] == dfResult['obscene'])\n",
    "             & (dfResult['ThreatPred'] == dfResult['threat']) & (dfResult['InsultPred'] == dfResult['insult']) & (dfResult['IdHatePred'] == dfResult['identity_hate'])) \n",
    "                                   & (dfResult['clean']==0)]\n",
    "    \n",
    "    predClean = dfResult[((dfResult['ToxicPred'] == 0) & (dfResult['SToxicPred'] == 0) & (dfResult['ObscenePred'] == 0)\n",
    "             & (dfResult['ThreatPred'] == 0) & (dfResult['InsultPred'] == 0) & (dfResult['IdHatePred'] == 0))]\n",
    "    \n",
    "    predCleanActClean = dfResult[((dfResult['ToxicPred'] == dfResult['toxic']) & (dfResult['SToxicPred'] == dfResult['severe_toxic']) & (dfResult['ObscenePred'] == dfResult['obscene'])\n",
    "             & (dfResult['ThreatPred'] == dfResult['threat']) & (dfResult['InsultPred'] == dfResult['insult']) & (dfResult['IdHatePred'] == dfResult['identity_hate'])) & (dfResult['clean']==1)]\n",
    "\n",
    "    predTrueActTrue = dfResult[(dfResult['ToxicPred'] == dfResult['toxic']) & (dfResult['SToxicPred'] == dfResult['severe_toxic']) & (dfResult['ObscenePred'] == dfResult['obscene']) & (dfResult['ThreatPred'] == dfResult['threat']) & (dfResult['InsultPred'] == dfResult['insult']) & (dfResult['IdHatePred'] == dfResult['identity_hate'])]\n",
    "\n",
    "    return actCancer, actClean, predCancer, predCancerActCancer, predClean, predCleanActClean, predTrueActTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "actCancer_train, actClean_train, predCancer_train, predCancerActCancer_train, predClean_train, predCleanActClean_train, predTrueActTrue_train = filter_dataframe(dfFinalTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_filter(actCancer, actClean, predCancer, predCancerActCancer, predClean, predCleanActClean,  predTrueActTrue):\n",
    "    print('Cancer = Data yang mengandung salah satu dari toxic, severe toxic, obscene, threat, insult, atau identity hate')\n",
    "    print('\\n')\n",
    "    print('Total Data di Dataframe = {}'.format(len(actCancer)+len(actClean)))\n",
    "    print('Banyak data Cancer = {}'.format(len(actCancer)))\n",
    "    print('Banyak data Clean = {}'.format(len(actClean)))\n",
    "    print('\\n')\n",
    "    print('Banyak Prediction Cancer yang benar = {}'.format(len(predCancerActCancer)))\n",
    "    print('Percentage dari Prediction Cancer yang benar = {}%'.format(len(predCancerActCancer)/len(actCancer)*100))\n",
    "    print('\\n')\n",
    "    print('Banyak Prediction Clean yang benar = {}'.format(len(predCleanActClean)))\n",
    "    print('Percentage dari Prediction Clean yang benar = {}%'.format(len(predCleanActClean)/len(actClean)*100))\n",
    "    print('\\n')\n",
    "    print('Banyak Prediction yang benar = {}'.format(len(predTrueActTrue)))\n",
    "    print('Percentage dari Prediction yang benar = {}%'.format(len(predTrueActTrue)/(len(actCancer)+len(actClean))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer = Data yang mengandung salah satu dari toxic, severe toxic, obscene, threat, insult, atau identity hate\n",
      "\n",
      "\n",
      "Total Data di Dataframe = 111699\n",
      "Banyak data Cancer = 11358\n",
      "Banyak data Clean = 100341\n",
      "\n",
      "\n",
      "Banyak Prediction Cancer yang benar = 1769\n",
      "Percentage dari Prediction Cancer yang benar = 15.57492516288079%\n",
      "\n",
      "\n",
      "Banyak Prediction Clean yang benar = 100073\n",
      "Percentage dari Prediction Clean yang benar = 99.73291077425978%\n",
      "\n",
      "\n",
      "Banyak Prediction yang benar = 101842\n",
      "Percentage dari Prediction yang benar = 91.17539100618627%\n"
     ]
    }
   ],
   "source": [
    "print_filter(actCancer_train, actClean_train, predCancer_train, predCancerActCancer_train, predClean_train, predCleanActClean_train, predTrueActTrue_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11358, 100341, 6972, 104727)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actCancer = dfFinalTrain[dfFinalTrain['clean']==0]\n",
    "actClean = dfFinalTrain[dfFinalTrain['clean']==1]\n",
    "predCancer = dfFinalTrain[dfFinalTrain['cleanPred']==0]\n",
    "predClean = dfFinalTrain[dfFinalTrain['cleanPred']==1]\n",
    "\n",
    "len(actCancer), len(actClean), len(predCancer), len(predClean), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1769, 100073, 1769, 100073)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actCancer2 = dfFinalTrain[(dfFinalTrain['clean']==0) & ((dfFinalTrain['ToxicPred'] == dfFinalTrain['toxic']) & (dfFinalTrain['SToxicPred'] == dfFinalTrain['severe_toxic']) & (dfFinalTrain['ObscenePred'] == dfFinalTrain['obscene']) & (dfFinalTrain['ThreatPred'] == dfFinalTrain['threat']) & (dfFinalTrain['InsultPred'] == dfFinalTrain['insult']) & (dfFinalTrain['IdHatePred'] == dfFinalTrain['identity_hate']))]\n",
    "actClean2 = dfFinalTrain[(dfFinalTrain['clean']==1) & ((dfFinalTrain['ToxicPred'] == dfFinalTrain['toxic']) & (dfFinalTrain['SToxicPred'] == dfFinalTrain['severe_toxic']) & (dfFinalTrain['ObscenePred'] == dfFinalTrain['obscene']) & (dfFinalTrain['ThreatPred'] == dfFinalTrain['threat']) & (dfFinalTrain['InsultPred'] == dfFinalTrain['insult']) & (dfFinalTrain['IdHatePred'] == dfFinalTrain['identity_hate']))]\n",
    "predCancer2 = dfFinalTrain[(dfFinalTrain['cleanPred']==0) & ((dfFinalTrain['ToxicPred'] == dfFinalTrain['toxic']) & (dfFinalTrain['SToxicPred'] == dfFinalTrain['severe_toxic']) & (dfFinalTrain['ObscenePred'] == dfFinalTrain['obscene']) & (dfFinalTrain['ThreatPred'] == dfFinalTrain['threat']) & (dfFinalTrain['InsultPred'] == dfFinalTrain['insult']) & (dfFinalTrain['IdHatePred'] == dfFinalTrain['identity_hate']))]\n",
    "predClean2 = dfFinalTrain[(dfFinalTrain['cleanPred']==1) & ((dfFinalTrain['ToxicPred'] == dfFinalTrain['toxic']) & (dfFinalTrain['SToxicPred'] == dfFinalTrain['severe_toxic']) & (dfFinalTrain['ObscenePred'] == dfFinalTrain['obscene']) & (dfFinalTrain['ThreatPred'] == dfFinalTrain['threat']) & (dfFinalTrain['InsultPred'] == dfFinalTrain['insult']) & (dfFinalTrain['IdHatePred'] == dfFinalTrain['identity_hate']))]\n",
    "\n",
    "len(actCancer2), len(actClean2), len(predCancer2), len(predClean2), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# 1684 9674 = 11358\n",
    "# 222 100119 = 100 341\n",
    "# 6790 104909 101803"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dPredict_test = {}\n",
    "dPredictProba_test = {}\n",
    "dResult_test = {}\n",
    "\n",
    "for category in categories:\n",
    "    pipeline_predict(category, dPredict_test, dPredictProba_test, dResult_test, x_test, y_test[category])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Test F1 Score</th>\n",
       "      <th>Test Log Loss</th>\n",
       "      <th>Test ROC AUC</th>\n",
       "      <th>Test Matthew Corr Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.905853</td>\n",
       "      <td>0.491986</td>\n",
       "      <td>0.395822</td>\n",
       "      <td>0.898878</td>\n",
       "      <td>0.121359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.989576</td>\n",
       "      <td>0.557343</td>\n",
       "      <td>0.036930</td>\n",
       "      <td>0.965534</td>\n",
       "      <td>0.168217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.947673</td>\n",
       "      <td>0.511576</td>\n",
       "      <td>0.202670</td>\n",
       "      <td>0.929993</td>\n",
       "      <td>0.139435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.995634</td>\n",
       "      <td>0.517339</td>\n",
       "      <td>0.019694</td>\n",
       "      <td>0.934112</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.951245</td>\n",
       "      <td>0.515019</td>\n",
       "      <td>0.189308</td>\n",
       "      <td>0.928008</td>\n",
       "      <td>0.149289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.991874</td>\n",
       "      <td>0.618815</td>\n",
       "      <td>0.028702</td>\n",
       "      <td>0.971729</td>\n",
       "      <td>0.329301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category  Test Acc  Test F1 Score  Test Log Loss  Test ROC AUC  \\\n",
       "0          toxic  0.905853       0.491986       0.395822      0.898878   \n",
       "1   severe_toxic  0.989576       0.557343       0.036930      0.965534   \n",
       "2        obscene  0.947673       0.511576       0.202670      0.929993   \n",
       "3         threat  0.995634       0.517339       0.019694      0.934112   \n",
       "4         insult  0.951245       0.515019       0.189308      0.928008   \n",
       "5  identity_hate  0.991874       0.618815       0.028702      0.971729   \n",
       "\n",
       "   Test Matthew Corr Coef  \n",
       "0                0.121359  \n",
       "1                0.168217  \n",
       "2                0.139435  \n",
       "3                0.036000  \n",
       "4                0.149289  \n",
       "5                0.329301  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfReportTest = bikin_report(dResult_test, 'dfReportTest', 'Test')\n",
    "dfReportTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Test F1 Score</th>\n",
       "      <th>Test Log Loss</th>\n",
       "      <th>Test ROC AUC</th>\n",
       "      <th>Test Matthew Corr Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.963643</td>\n",
       "      <td>0.535346</td>\n",
       "      <td>0.145521</td>\n",
       "      <td>0.938042</td>\n",
       "      <td>0.157267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.035331</td>\n",
       "      <td>0.046116</td>\n",
       "      <td>0.147719</td>\n",
       "      <td>0.026853</td>\n",
       "      <td>0.096013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.905853</td>\n",
       "      <td>0.491986</td>\n",
       "      <td>0.019694</td>\n",
       "      <td>0.898878</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.948566</td>\n",
       "      <td>0.512437</td>\n",
       "      <td>0.030759</td>\n",
       "      <td>0.928504</td>\n",
       "      <td>0.125878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.970411</td>\n",
       "      <td>0.516179</td>\n",
       "      <td>0.113119</td>\n",
       "      <td>0.932053</td>\n",
       "      <td>0.144362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.991300</td>\n",
       "      <td>0.547342</td>\n",
       "      <td>0.199330</td>\n",
       "      <td>0.957678</td>\n",
       "      <td>0.163485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.995634</td>\n",
       "      <td>0.618815</td>\n",
       "      <td>0.395822</td>\n",
       "      <td>0.971729</td>\n",
       "      <td>0.329301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Test Acc  Test F1 Score  Test Log Loss  Test ROC AUC  \\\n",
       "count  6.000000       6.000000       6.000000      6.000000   \n",
       "mean   0.963643       0.535346       0.145521      0.938042   \n",
       "std    0.035331       0.046116       0.147719      0.026853   \n",
       "min    0.905853       0.491986       0.019694      0.898878   \n",
       "25%    0.948566       0.512437       0.030759      0.928504   \n",
       "50%    0.970411       0.516179       0.113119      0.932053   \n",
       "75%    0.991300       0.547342       0.199330      0.957678   \n",
       "max    0.995634       0.618815       0.395822      0.971729   \n",
       "\n",
       "       Test Matthew Corr Coef  \n",
       "count                6.000000  \n",
       "mean                 0.157267  \n",
       "std                  0.096013  \n",
       "min                  0.036000  \n",
       "25%                  0.125878  \n",
       "50%                  0.144362  \n",
       "75%                  0.163485  \n",
       "max                  0.329301  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfReportTest.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ToxicPred</th>\n",
       "      <th>SToxicPred</th>\n",
       "      <th>ObscenePred</th>\n",
       "      <th>ThreatPred</th>\n",
       "      <th>InsultPred</th>\n",
       "      <th>IdHatePred</th>\n",
       "      <th>cleanPred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ToxicPred  SToxicPred  ObscenePred  ThreatPred  InsultPred  IdHatePred  \\\n",
       "0          0           0            0           0           0           0   \n",
       "1          0           0            0           0           0           0   \n",
       "2          0           0            0           0           0           0   \n",
       "3          0           0            0           0           0           0   \n",
       "4          0           0            0           0           0           0   \n",
       "5          0           0            0           0           0           0   \n",
       "6          0           0            0           0           0           0   \n",
       "7          0           0            0           0           0           0   \n",
       "\n",
       "   cleanPred  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  \n",
       "6          1  \n",
       "7          1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResultTest = bikin_hasil_pred(dPredict_test, 'dfResultTest')\n",
    "dfResultTest.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinalTest = combine_predict_with_keylabel('dfFinalTest', dfResultTest, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ToxicPred</th>\n",
       "      <th>SToxicPred</th>\n",
       "      <th>ObscenePred</th>\n",
       "      <th>ThreatPred</th>\n",
       "      <th>InsultPred</th>\n",
       "      <th>IdHatePred</th>\n",
       "      <th>cleanPred</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ToxicPred  SToxicPred  ObscenePred  ThreatPred  InsultPred  IdHatePred  \\\n",
       "0          0           0            0           0           0           0   \n",
       "1          0           0            0           0           0           0   \n",
       "2          0           0            0           0           0           0   \n",
       "3          0           0            0           0           0           0   \n",
       "4          0           0            0           0           0           0   \n",
       "\n",
       "   cleanPred  toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0          1      0             0        0       0       0              0   \n",
       "1          1      0             0        0       0       0              0   \n",
       "2          1      0             0        0       0       0              0   \n",
       "3          1      0             0        0       0       0              0   \n",
       "4          1      0             0        0       0       0              0   \n",
       "\n",
       "   clean  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinalTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "actCancer_test, actClean_test, predCancer_test, predCancerActCancer_test, predClean_test, predCleanActClean_test, predTrueActTrue_test = filter_dataframe(dfFinalTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer = Data yang mengandung salah satu dari toxic, severe toxic, obscene, threat, insult, atau identity hate\n",
      "\n",
      "\n",
      "Total Data di Dataframe = 47872\n",
      "Banyak data Cancer = 4867\n",
      "Banyak data Clean = 43005\n",
      "\n",
      "\n",
      "Banyak Prediction Cancer yang benar = 0\n",
      "Percentage dari Prediction Cancer yang benar = 0.0%\n",
      "\n",
      "\n",
      "Banyak Prediction Clean yang benar = 43002\n",
      "Percentage dari Prediction Clean yang benar = 99.99302406696896%\n",
      "\n",
      "\n",
      "Banyak Prediction yang benar = 43002\n",
      "Percentage dari Prediction yang benar = 89.82703877005348%\n"
     ]
    }
   ],
   "source": [
    "print_filter(actCancer_test, actClean_test, predCancer_test, predCancerActCancer_test, predClean_test, predCleanActClean_test, predTrueActTrue_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_final = vectorizer.transform(final['comment_text'])\n",
    "y_final = final.drop(labels = ['id','comment_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dPredict_final = {}\n",
    "dPredictProba_final = {}\n",
    "dResult_final = {}\n",
    "\n",
    "for category in categories:\n",
    "    pipeline_predict(category, dPredict_final, dPredictProba_final, dResult_final, x_final, y_final[category])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Final Acc</th>\n",
       "      <th>Final F1 Score</th>\n",
       "      <th>Final Log Loss</th>\n",
       "      <th>Final ROC AUC</th>\n",
       "      <th>Final Matthew Corr Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.906874</td>\n",
       "      <td>0.502056</td>\n",
       "      <td>0.372727</td>\n",
       "      <td>0.905306</td>\n",
       "      <td>0.140286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.992794</td>\n",
       "      <td>0.593094</td>\n",
       "      <td>0.025303</td>\n",
       "      <td>0.975413</td>\n",
       "      <td>0.194940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.943402</td>\n",
       "      <td>0.520341</td>\n",
       "      <td>0.213665</td>\n",
       "      <td>0.920549</td>\n",
       "      <td>0.148585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.993795</td>\n",
       "      <td>0.517814</td>\n",
       "      <td>0.024234</td>\n",
       "      <td>0.942090</td>\n",
       "      <td>0.035638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.947748</td>\n",
       "      <td>0.525960</td>\n",
       "      <td>0.197826</td>\n",
       "      <td>0.915951</td>\n",
       "      <td>0.163559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.990028</td>\n",
       "      <td>0.648474</td>\n",
       "      <td>0.032372</td>\n",
       "      <td>0.975166</td>\n",
       "      <td>0.360535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category  Final Acc  Final F1 Score  Final Log Loss  Final ROC AUC  \\\n",
       "0          toxic   0.906874        0.502056        0.372727       0.905306   \n",
       "1   severe_toxic   0.992794        0.593094        0.025303       0.975413   \n",
       "2        obscene   0.943402        0.520341        0.213665       0.920549   \n",
       "3         threat   0.993795        0.517814        0.024234       0.942090   \n",
       "4         insult   0.947748        0.525960        0.197826       0.915951   \n",
       "5  identity_hate   0.990028        0.648474        0.032372       0.975166   \n",
       "\n",
       "   Final Matthew Corr Coef  \n",
       "0                 0.140286  \n",
       "1                 0.194940  \n",
       "2                 0.148585  \n",
       "3                 0.035638  \n",
       "4                 0.163559  \n",
       "5                 0.360535  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfReportFinal = bikin_report(dResult_final, 'dfReportFinal', 'Final')\n",
    "dfReportFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Final Acc</th>\n",
       "      <th>Final F1 Score</th>\n",
       "      <th>Final Log Loss</th>\n",
       "      <th>Final ROC AUC</th>\n",
       "      <th>Final Matthew Corr Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.962440</td>\n",
       "      <td>0.551290</td>\n",
       "      <td>0.144355</td>\n",
       "      <td>0.939079</td>\n",
       "      <td>0.173924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.035585</td>\n",
       "      <td>0.057160</td>\n",
       "      <td>0.142098</td>\n",
       "      <td>0.030497</td>\n",
       "      <td>0.106084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.906874</td>\n",
       "      <td>0.502056</td>\n",
       "      <td>0.024234</td>\n",
       "      <td>0.905306</td>\n",
       "      <td>0.035638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.944489</td>\n",
       "      <td>0.518446</td>\n",
       "      <td>0.027070</td>\n",
       "      <td>0.917100</td>\n",
       "      <td>0.142361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.968888</td>\n",
       "      <td>0.523151</td>\n",
       "      <td>0.115099</td>\n",
       "      <td>0.931320</td>\n",
       "      <td>0.156072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.992103</td>\n",
       "      <td>0.576311</td>\n",
       "      <td>0.209705</td>\n",
       "      <td>0.966897</td>\n",
       "      <td>0.187094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.993795</td>\n",
       "      <td>0.648474</td>\n",
       "      <td>0.372727</td>\n",
       "      <td>0.975413</td>\n",
       "      <td>0.360535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Final Acc  Final F1 Score  Final Log Loss  Final ROC AUC  \\\n",
       "count   6.000000        6.000000        6.000000       6.000000   \n",
       "mean    0.962440        0.551290        0.144355       0.939079   \n",
       "std     0.035585        0.057160        0.142098       0.030497   \n",
       "min     0.906874        0.502056        0.024234       0.905306   \n",
       "25%     0.944489        0.518446        0.027070       0.917100   \n",
       "50%     0.968888        0.523151        0.115099       0.931320   \n",
       "75%     0.992103        0.576311        0.209705       0.966897   \n",
       "max     0.993795        0.648474        0.372727       0.975413   \n",
       "\n",
       "       Final Matthew Corr Coef  \n",
       "count                 6.000000  \n",
       "mean                  0.173924  \n",
       "std                   0.106084  \n",
       "min                   0.035638  \n",
       "25%                   0.142361  \n",
       "50%                   0.156072  \n",
       "75%                   0.187094  \n",
       "max                   0.360535  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfReportFinal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ToxicPred</th>\n",
       "      <th>SToxicPred</th>\n",
       "      <th>ObscenePred</th>\n",
       "      <th>ThreatPred</th>\n",
       "      <th>InsultPred</th>\n",
       "      <th>IdHatePred</th>\n",
       "      <th>cleanPred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ToxicPred  SToxicPred  ObscenePred  ThreatPred  InsultPred  IdHatePred  \\\n",
       "0          0           0            0           0           0           0   \n",
       "1          0           0            0           0           0           0   \n",
       "2          0           0            0           0           0           0   \n",
       "3          0           0            0           0           0           0   \n",
       "4          0           0            0           0           0           0   \n",
       "5          0           0            0           0           0           0   \n",
       "6          0           0            0           0           0           0   \n",
       "7          0           0            0           0           0           0   \n",
       "\n",
       "   cleanPred  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  \n",
       "6          1  \n",
       "7          1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResultFinal = bikin_hasil_pred(dPredict_final, 'dfResultFinal')\n",
    "dfResultFinal.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinalFinal = combine_predict_with_keylabel('dfFinalFinal', dfResultFinal, final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ToxicPred</th>\n",
       "      <th>SToxicPred</th>\n",
       "      <th>ObscenePred</th>\n",
       "      <th>ThreatPred</th>\n",
       "      <th>InsultPred</th>\n",
       "      <th>IdHatePred</th>\n",
       "      <th>cleanPred</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ToxicPred  SToxicPred  ObscenePred  ThreatPred  InsultPred  IdHatePred  \\\n",
       "0          0           0            0           0           0           0   \n",
       "1          0           0            0           0           0           0   \n",
       "2          0           0            0           0           0           0   \n",
       "3          0           0            0           0           0           0   \n",
       "4          0           0            0           0           0           0   \n",
       "\n",
       "   cleanPred  toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0          1      0             0        0       0       0              0   \n",
       "1          1      0             0        0       0       0              0   \n",
       "2          1      0             0        0       0       0              0   \n",
       "3          1      0             0        0       0       0              0   \n",
       "4          1      0             0        0       0       0              0   \n",
       "\n",
       "   clean  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinalFinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "actCancer_final, actClean_final, predCancer_final, predCancerActCancer_final, predClean_final, predCleanActClean_final, predTrueActTrue_final = filter_dataframe(dfFinalFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer = Data yang mengandung salah satu dari toxic, severe toxic, obscene, threat, insult, atau identity hate\n",
      "\n",
      "\n",
      "Total Data di Dataframe = 63978\n",
      "Banyak data Cancer = 6243\n",
      "Banyak data Clean = 57735\n",
      "\n",
      "\n",
      "Banyak Prediction Cancer yang benar = 4\n",
      "Percentage dari Prediction Cancer yang benar = 0.06407176037161622%\n",
      "\n",
      "\n",
      "Banyak Prediction Clean yang benar = 57702\n",
      "Percentage dari Prediction Clean yang benar = 99.94284229670043%\n",
      "\n",
      "\n",
      "Banyak Prediction yang benar = 57706\n",
      "Percentage dari Prediction yang benar = 90.19663009159399%\n"
     ]
    }
   ],
   "source": [
    "print_filter(actCancer_final, actClean_final, predCancer_final, predCancerActCancer_final, predClean_final, predCleanActClean_final, predTrueActTrue_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic_accuracy',\n",
       " 'toxic_f1score',\n",
       " 'toxic_logloss',\n",
       " 'toxic_rocauc',\n",
       " 'toxic_matthews_corrcoef',\n",
       " 'toxic_classification_report',\n",
       " 'toxic_confusion_matrix',\n",
       " 'severe_toxic_accuracy',\n",
       " 'severe_toxic_f1score',\n",
       " 'severe_toxic_logloss',\n",
       " 'severe_toxic_rocauc',\n",
       " 'severe_toxic_matthews_corrcoef',\n",
       " 'severe_toxic_classification_report',\n",
       " 'severe_toxic_confusion_matrix',\n",
       " 'obscene_accuracy',\n",
       " 'obscene_f1score',\n",
       " 'obscene_logloss',\n",
       " 'obscene_rocauc',\n",
       " 'obscene_matthews_corrcoef',\n",
       " 'obscene_classification_report',\n",
       " 'obscene_confusion_matrix',\n",
       " 'threat_accuracy',\n",
       " 'threat_f1score',\n",
       " 'threat_logloss',\n",
       " 'threat_rocauc',\n",
       " 'threat_matthews_corrcoef',\n",
       " 'threat_classification_report',\n",
       " 'threat_confusion_matrix',\n",
       " 'insult_accuracy',\n",
       " 'insult_f1score',\n",
       " 'insult_logloss',\n",
       " 'insult_rocauc',\n",
       " 'insult_matthews_corrcoef',\n",
       " 'insult_classification_report',\n",
       " 'insult_confusion_matrix',\n",
       " 'identity_hate_accuracy',\n",
       " 'identity_hate_f1score',\n",
       " 'identity_hate_logloss',\n",
       " 'identity_hate_rocauc',\n",
       " 'identity_hate_matthews_corrcoef',\n",
       " 'identity_hate_classification_report',\n",
       " 'identity_hate_confusion_matrix']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dResult_final.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     57888\n",
      "           1       0.83      0.03      0.05      6090\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     63978\n",
      "   macro avg       0.87      0.51      0.50     63978\n",
      "weighted avg       0.90      0.91      0.87     63978\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     57888\n",
      "           1       0.83      0.03      0.05      6090\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     63978\n",
      "   macro avg       0.87      0.51      0.50     63978\n",
      "weighted avg       0.90      0.91      0.87     63978\n",
      "\n",
      "\n",
      "\n",
      "severe_toxic\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63611\n",
      "           1       0.27      0.15      0.19       367\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     63978\n",
      "   macro avg       0.63      0.57      0.59     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63611\n",
      "           1       0.27      0.15      0.19       367\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     63978\n",
      "   macro avg       0.63      0.57      0.59     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n",
      "\n",
      "\n",
      "obscene\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     60287\n",
      "           1       0.67      0.04      0.07      3691\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     63978\n",
      "   macro avg       0.81      0.52      0.52     63978\n",
      "weighted avg       0.93      0.94      0.92     63978\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     60287\n",
      "           1       0.67      0.04      0.07      3691\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     63978\n",
      "   macro avg       0.81      0.52      0.52     63978\n",
      "weighted avg       0.93      0.94      0.92     63978\n",
      "\n",
      "\n",
      "\n",
      "threat\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63767\n",
      "           1       0.04      0.04      0.04       211\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     63978\n",
      "   macro avg       0.52      0.52      0.52     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63767\n",
      "           1       0.04      0.04      0.04       211\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     63978\n",
      "   macro avg       0.52      0.52      0.52     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n",
      "\n",
      "\n",
      "insult\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     60551\n",
      "           1       0.71      0.04      0.08      3427\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     63978\n",
      "   macro avg       0.83      0.52      0.53     63978\n",
      "weighted avg       0.94      0.95      0.93     63978\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     60551\n",
      "           1       0.71      0.04      0.08      3427\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     63978\n",
      "   macro avg       0.83      0.52      0.53     63978\n",
      "weighted avg       0.94      0.95      0.93     63978\n",
      "\n",
      "\n",
      "\n",
      "identity_hate\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     63266\n",
      "           1       0.68      0.19      0.30       712\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     63978\n",
      "   macro avg       0.84      0.60      0.65     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     63266\n",
      "           1       0.68      0.19      0.30       712\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     63978\n",
      "   macro avg       0.84      0.60      0.65     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "    print(str(category))\n",
    "    print(dResult_final['{}_confusion_matrix'.format(category)])\n",
    "    print(dResult_final['{}_classification_report'.format(category)])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
