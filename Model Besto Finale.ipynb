{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import pickle\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_csv('dfMaster.csv')\n",
    "train = pd.read_csv('trainMaster.csv')\n",
    "final = pd.read_csv('dfTestDataLabelFinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>toxic_level</th>\n",
       "      <th>clean</th>\n",
       "      <th>length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>264</td>\n",
       "      <td>43</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>18</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>233</td>\n",
       "      <td>42</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.406667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\" More I can't make any real suggestions on im...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>622</td>\n",
       "      <td>116</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.301042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation Why the edits made under my userna...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \" More I can't make any real suggestions on im...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  toxic_level  clean  length  \\\n",
       "0        0       0       0              0            0      1     264   \n",
       "1        0       0       0              0            0      1     112   \n",
       "2        0       0       0              0            0      1     233   \n",
       "3        0       0       0              0            0      1     622   \n",
       "4        0       0       0              0            0      1      67   \n",
       "\n",
       "   word_count  polarity  subjectivity  \n",
       "0          43  0.136364      0.454545  \n",
       "1          18  0.287500      0.550000  \n",
       "2          42  0.160000      0.406667  \n",
       "3         116  0.200000      0.301042  \n",
       "4          13  0.000000      0.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>toxic_level</th>\n",
       "      <th>clean</th>\n",
       "      <th>length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>16</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>448</td>\n",
       "      <td>69</td>\n",
       "      <td>-0.001562</td>\n",
       "      <td>0.576563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>\" More I can't make any real suggestions on im...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>501</td>\n",
       "      <td>85</td>\n",
       "      <td>0.151948</td>\n",
       "      <td>0.406494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>334</td>\n",
       "      <td>57</td>\n",
       "      <td>0.286580</td>\n",
       "      <td>0.631457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0001ea8717f6de06  Explanation Why the edits made under my userna...      0   \n",
       "1  000247e83dcc1211  D'aww! He matches this background colour I'm s...      0   \n",
       "2  0002f87b16116a7f  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0003e1cccfd5a40a  \" More I can't make any real suggestions on im...      0   \n",
       "4  00059ace3e3e9a53  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  toxic_level  clean  \\\n",
       "0             0        0       0       0              0            0      1   \n",
       "1             0        0       0       0              0            0      1   \n",
       "2             0        0       0       0              0            0      1   \n",
       "3             0        0       0       0              0            0      1   \n",
       "4             0        0       0       0              0            0      1   \n",
       "\n",
       "   length  word_count  polarity  subjectivity  \n",
       "0      96          16  0.208000      0.702000  \n",
       "1      32           6 -1.000000      1.000000  \n",
       "2     448          69 -0.001562      0.576563  \n",
       "3     501          85  0.151948      0.406494  \n",
       "4     334          57  0.286580      0.631457  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ReviewText):\n",
    "    ReviewText = ReviewText.str.replace(\"(<br/>)\", \"\")\n",
    "    ReviewText = ReviewText.str.replace('(<a).*(>).*(</a>)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&amp)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&gt)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&lt)', '')\n",
    "    ReviewText = ReviewText.str.replace('(\\xa0)', ' ')\n",
    "    ReviewText = ReviewText.str.replace('(\\n)', ' ') \n",
    "    ReviewText = ReviewText.str.replace('==', ' ') \n",
    "    return ReviewText\n",
    "\n",
    "master['comment_text'] = preprocess(master['comment_text'])\n",
    "train['comment_text'] = preprocess(train['comment_text'])\n",
    "final['comment_text'] = preprocess(master['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train['comment_text']\n",
    "\n",
    "categories = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, matthews_corrcoef, f1_score, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzer for Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = []\n",
    "for words in stopwords.words('english'):\n",
    "    s = [char for char in words if char not in string.punctuation]\n",
    "    stop.append(''.join(s))\n",
    "stop.extend(['may','also','across','among','beside','however','yet','within'])\n",
    "\n",
    "def process_nocasepunc(text):\n",
    "    nocasepunc = [char for char in text if char not in string.punctuation]\n",
    "    nocasepunc = ''.join(nocasepunc)\n",
    "    return [word.lower() for word in nocasepunc.split() if word.lower() not in stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_pipeline_toxic = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=30000)),\n",
    "            ('classifier', LogisticRegression()),\n",
    "        ])\n",
    "LogReg_pipeline_severe_toxic = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=30000)),\n",
    "            ('classifier', LogisticRegression()),\n",
    "        ])\n",
    "LogReg_pipeline_obscene = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=30000)),\n",
    "            ('classifier', LogisticRegression()),\n",
    "        ])\n",
    "LogReg_pipeline_threat = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=30000)),\n",
    "            ('classifier', LogisticRegression()),\n",
    "        ])\n",
    "LogReg_pipeline_insult = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=30000)),\n",
    "            ('classifier', LogisticRegression()),\n",
    "        ])\n",
    "LogReg_pipeline_identity_hate = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=30000)),\n",
    "            ('classifier', LogisticRegression()),\n",
    "        ])\n",
    "\n",
    "# # def pipeline_model_training(category, dataTrain, targetTrain):\n",
    "# #     # Training logistic regression model on train data\n",
    "# #     return LogReg_pipeline.fit(dataTrain, targetTrain)\n",
    "\n",
    "# # def pipeline_predict(category, dictPred, dictPredProba, dictHasil, dataTest, targetTest):\n",
    "# #     # calculating test accuracy\n",
    "# #     prediction = LogReg_pipeline.predict(dataTest)\n",
    "# #     dictPredProba['{}'.format(category)] = LogReg_pipeline.predict_proba(dataTest)\n",
    "# #     dictPred[category] = prediction \n",
    "# #     dictHasil['{}_accuracy'.format(category)] = accuracy_score(targetTest, prediction)\n",
    "# #     dictHasil['{}_f1score'.format(category)] = f1_score(targetTest, prediction, average = 'macro')\n",
    "# #     dictHasil['{}_logloss'.format(category)] = log_loss(targetTest, dictPredProba[category])\n",
    "# #     dictHasil['{}_rocauc'.format(category)] = roc_auc_score(targetTest, dictPredProba[category][:,1])\n",
    "# #     dictHasil['{}_matthews_corrcoef'.format(category)] = matthews_corrcoef(targetTest, prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=30000, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg_pipeline_clean = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=30000)),\n",
    "            ('classifier', LogisticRegression()),\n",
    "        ])\n",
    "LogReg_pipeline_clean.fit(train['comment_text'],train['clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictClean = LogReg_pipeline_clean.predict(final['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm pretty sure the incident has already been included. And I know how to handle my own at riots, too. 8)\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[final['clean']==0]['comment_text'].iloc[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.07      0.08      6243\n",
      "           1       0.90      0.93      0.92     57735\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     63978\n",
      "   macro avg       0.50      0.50      0.50     63978\n",
      "weighted avg       0.82      0.85      0.83     63978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(final['clean'], predictClean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogReg_pipeline_toxic.fit(master['comment_text'],master['toxic'])\n",
    "# LogReg_pipeline_severe_toxic.fit(master['comment_text'],master['severe_toxic'])\n",
    "# LogReg_pipeline_obscene.fit(master['comment_text'],master['obscene'])\n",
    "# LogReg_pipeline_threat.fit(master['comment_text'],master['threat'])\n",
    "# LogReg_pipeline_insult.fit(master['comment_text'],master['insult'])\n",
    "# LogReg_pipeline_identity_hate.fit(master['comment_text'],master['identity_hate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(LogReg_pipeline_toxic, open('LogReg_pipeline_toxic.sav','wb'))\n",
    "# pickle.dump(LogReg_pipeline_severe_toxic, open('LogReg_pipeline_severe_toxic.sav','wb'))\n",
    "# pickle.dump(LogReg_pipeline_obscene, open('LogReg_pipeline_obscene.sav','wb'))\n",
    "# pickle.dump(LogReg_pipeline_threat, open('LogReg_pipeline_threat.sav','wb'))\n",
    "# pickle.dump(LogReg_pipeline_insult, open('LogReg_pipeline_insult.sav','wb'))\n",
    "# pickle.dump(LogReg_pipeline_identity_hate, open('LogReg_pipeline_identity_hate.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_pipeline_toxic = pickle.load(open('LogReg_pipeline_toxic.sav','rb'))\n",
    "LogReg_pipeline_severe_toxic = pickle.load(open('LogReg_pipeline_severe_toxic.sav','rb'))\n",
    "LogReg_pipeline_obscene = pickle.load(open('LogReg_pipeline_obscene.sav','rb'))\n",
    "LogReg_pipeline_threat = pickle.load(open('LogReg_pipeline_threat.sav','rb'))\n",
    "LogReg_pipeline_insult = pickle.load(open('LogReg_pipeline_insult.sav','rb'))\n",
    "LogReg_pipeline_identity_hate = pickle.load(open('LogReg_pipeline_identity_hate.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text):\n",
    "    hasil =[]\n",
    "    proba = []\n",
    "    proba.append(LogReg_pipeline_toxic.predict_proba([text])[0][1])\n",
    "    proba.append(LogReg_pipeline_severe_toxic.predict_proba([text])[0][1])\n",
    "    proba.append(LogReg_pipeline_obscene.predict_proba([text])[0][1])\n",
    "    proba.append(LogReg_pipeline_threat.predict_proba([text])[0][1])\n",
    "    proba.append(LogReg_pipeline_insult.predict_proba([text])[0][1])\n",
    "    proba.append(LogReg_pipeline_identity_hate.predict_proba([text])[0][1])\n",
    "    if LogReg_pipeline_toxic.predict([text])[0]==1:\n",
    "        hasil.append('toxic')\n",
    "    if LogReg_pipeline_severe_toxic.predict([text])[0]==1:\n",
    "        hasil.append('severe toxic')\n",
    "    if LogReg_pipeline_obscene.predict([text])[0]==1:\n",
    "        hasil.append('obscene')\n",
    "    if LogReg_pipeline_threat.predict([text])[0]==1:\n",
    "        hasil.append('threat')\n",
    "    if LogReg_pipeline_insult.predict([text])[0]==1:\n",
    "        hasil.append('insult')\n",
    "    if LogReg_pipeline_identity_hate.predict([text])[0]==1:\n",
    "        hasil.append('identity hate')\n",
    "        \n",
    "    if(len(hasil)==0):\n",
    "        textpred = 'This text is clean ^^'\n",
    "    elif(len(hasil)==1):\n",
    "        textpred = 'In conclusion, we predict that this text is a TOXIC text that contains {} content'.format(hasil[0])\n",
    "    elif(len(hasil)==2):\n",
    "        textpred = 'In conclusion, we predict that this text is a TOXIC text that contains {} and {} contents'.format(hasil[0],hasil[1])\n",
    "    else:\n",
    "        textpred = 'In conclusion, we predict that this text is a TOXIC text that contains {}, and {} contents'.format(', '.join(hasil[:-1]), hasil[-1])\n",
    "    \n",
    "    print('This text have probabilities of being toxic({}%), severe toxic({}%), obscene({}%), threat({}%), insult({}%), and identity hate({}%)'.format(round(proba[0]*100,2),round(proba[1]*100,2),round(proba[2]*100,2),round(proba[3]*100,2),round(proba[4]*100,2),round(proba[5]*100,2)))\n",
    "    print(textpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text have probabilities of being toxic(99.98%), severe toxic(37.65%), obscene(99.96%), threat(0.69%), insult(99.94%), and identity hate(3.96%)\n",
      "In conclusion, we predict that this text is a TOXIC text that contains toxic, obscene, and insult contents\n"
     ]
    }
   ],
   "source": [
    "text = 'you are asshole'\n",
    "predict_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
