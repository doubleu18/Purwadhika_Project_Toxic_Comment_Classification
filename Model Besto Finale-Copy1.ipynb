{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import pickle\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_csv('dfMaster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ReviewText):\n",
    "    ReviewText = ReviewText.str.replace(\"(<br/>)\", \"\")\n",
    "    ReviewText = ReviewText.str.replace('(<a).*(>).*(</a>)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&amp)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&gt)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&lt)', '')\n",
    "    ReviewText = ReviewText.str.replace('(\\xa0)', ' ')\n",
    "    ReviewText = ReviewText.str.replace('(\\n)', ' ') \n",
    "    ReviewText = ReviewText.str.replace('==', ' ') \n",
    "    return ReviewText\n",
    "\n",
    "master['comment_text'] = preprocess(master['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = master['comment_text']\n",
    "\n",
    "categories = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, matthews_corrcoef, f1_score, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzer for Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = []\n",
    "for words in stopwords.words('english'):\n",
    "    s = [char for char in words if char not in string.punctuation]\n",
    "    stop.append(''.join(s))\n",
    "stop.extend(['may','also','across','among','beside','however','yet','within'])\n",
    "\n",
    "def process_nocasepunc(text):\n",
    "    nocasepunc = [char for char in text if char not in string.punctuation]\n",
    "    nocasepunc = ''.join(nocasepunc)\n",
    "    return [word.lower() for word in nocasepunc.split() if word.lower() not in stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_pipeline_toxic = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=30000)),\n",
    "            ('classifier', LogisticRegression()),\n",
    "        ])\n",
    "LogReg_pipeline_severe_toxic = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=30000)),\n",
    "            ('classifier', LogisticRegression()),\n",
    "        ])\n",
    "LogReg_pipeline_obscene = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=30000)),\n",
    "            ('classifier', LogisticRegression()),\n",
    "        ])\n",
    "LogReg_pipeline_threat = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=30000)),\n",
    "            ('classifier', LogisticRegression()),\n",
    "        ])\n",
    "LogReg_pipeline_insult = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=30000)),\n",
    "            ('classifier', LogisticRegression()),\n",
    "        ])\n",
    "LogReg_pipeline_identity_hate = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=30000)),\n",
    "            ('classifier', LogisticRegression()),\n",
    "        ])\n",
    "\n",
    "# # def pipeline_model_training(category, dataTrain, targetTrain):\n",
    "# #     # Training logistic regression model on train data\n",
    "# #     return LogReg_pipeline.fit(dataTrain, targetTrain)\n",
    "\n",
    "# # def pipeline_predict(category, dictPred, dictPredProba, dictHasil, dataTest, targetTest):\n",
    "# #     # calculating test accuracy\n",
    "# #     prediction = LogReg_pipeline.predict(dataTest)\n",
    "# #     dictPredProba['{}'.format(category)] = LogReg_pipeline.predict_proba(dataTest)\n",
    "# #     dictPred[category] = prediction \n",
    "# #     dictHasil['{}_accuracy'.format(category)] = accuracy_score(targetTest, prediction)\n",
    "# #     dictHasil['{}_f1score'.format(category)] = f1_score(targetTest, prediction, average = 'macro')\n",
    "# #     dictHasil['{}_logloss'.format(category)] = log_loss(targetTest, dictPredProba[category])\n",
    "# #     dictHasil['{}_rocauc'.format(category)] = roc_auc_score(targetTest, dictPredProba[category][:,1])\n",
    "# #     dictHasil['{}_matthews_corrcoef'.format(category)] = matthews_corrcoef(targetTest, prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogReg_pipeline_toxic.fit(master['comment_text'],master['toxic'])\n",
    "# LogReg_pipeline_severe_toxic.fit(master['comment_text'],master['severe_toxic'])\n",
    "# LogReg_pipeline_obscene.fit(master['comment_text'],master['obscene'])\n",
    "# LogReg_pipeline_threat.fit(master['comment_text'],master['threat'])\n",
    "# LogReg_pipeline_insult.fit(master['comment_text'],master['insult'])\n",
    "# LogReg_pipeline_identity_hate.fit(master['comment_text'],master['identity_hate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(LogReg_pipeline_toxic, open('LogReg_pipeline_toxic.sav','wb'))\n",
    "# pickle.dump(LogReg_pipeline_severe_toxic, open('LogReg_pipeline_severe_toxic.sav','wb'))\n",
    "# pickle.dump(LogReg_pipeline_obscene, open('LogReg_pipeline_obscene.sav','wb'))\n",
    "# pickle.dump(LogReg_pipeline_threat, open('LogReg_pipeline_threat.sav','wb'))\n",
    "# pickle.dump(LogReg_pipeline_insult, open('LogReg_pipeline_insult.sav','wb'))\n",
    "# pickle.dump(LogReg_pipeline_identity_hate, open('LogReg_pipeline_identity_hate.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_pipeline_toxic = pickle.load(open('LogReg_pipeline_toxic.sav','rb'))\n",
    "LogReg_pipeline_severe_toxic = pickle.load(open('LogReg_pipeline_severe_toxic.sav','rb'))\n",
    "LogReg_pipeline_obscene = pickle.load(open('LogReg_pipeline_obscene.sav','rb'))\n",
    "LogReg_pipeline_threat = pickle.load(open('LogReg_pipeline_threat.sav','rb'))\n",
    "LogReg_pipeline_insult = pickle.load(open('LogReg_pipeline_insult.sav','rb'))\n",
    "LogReg_pipeline_identity_hate = pickle.load(open('LogReg_pipeline_identity_hate.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text):\n",
    "    hasil =[]\n",
    "    proba = []\n",
    "    proba.append(LogReg_pipeline_toxic.predict_proba([text])[0][1])\n",
    "    proba.append(LogReg_pipeline_severe_toxic.predict_proba([text])[0][1])\n",
    "    proba.append(LogReg_pipeline_obscene.predict_proba([text])[0][1])\n",
    "    proba.append(LogReg_pipeline_threat.predict_proba([text])[0][1])\n",
    "    proba.append(LogReg_pipeline_insult.predict_proba([text])[0][1])\n",
    "    proba.append(LogReg_pipeline_identity_hate.predict_proba([text])[0][1])\n",
    "    if LogReg_pipeline_toxic.predict([text])[0]==1:\n",
    "        hasil.append('toxic')\n",
    "    if LogReg_pipeline_severe_toxic.predict([text])[0]==1:\n",
    "        hasil.append('severe toxic')\n",
    "    if LogReg_pipeline_obscene.predict([text])[0]==1:\n",
    "        hasil.append('obscene')\n",
    "    if LogReg_pipeline_threat.predict([text])[0]==1:\n",
    "        hasil.append('threat')\n",
    "    if LogReg_pipeline_insult.predict([text])[0]==1:\n",
    "        hasil.append('insult')\n",
    "    if LogReg_pipeline_identity_hate.predict([text])[0]==1:\n",
    "        hasil.append('identity hate')\n",
    "        \n",
    "    if(len(hasil)==0):\n",
    "        textpred = 'This text is clean ^^'\n",
    "    elif(len(hasil)==1):\n",
    "        textpred = 'In conclusion, we predict that this text is a TOXIC text that contains {} content'.format(hasil[0])\n",
    "    elif(len(hasil)==2):\n",
    "        textpred = 'In conclusion, we predict that this text is a TOXIC text that contains {} and {} contents'.format(hasil[0],hasil[1])\n",
    "    else:\n",
    "        textpred = 'In conclusion, we predict that this text is a TOXIC text that contains {}, and {} contents'.format(', '.join(hasil[:-1]), hasil[-1])\n",
    "    \n",
    "    print('This text have probabilities of being toxic({}%), severe toxic({}%), obscene({}%), threat({}%), insult({}%), and identity hate({}%)'.format(round(proba[0]*100,2),round(proba[1]*100,2),round(proba[2]*100,2),round(proba[3]*100,2),round(proba[4]*100,2),round(proba[5]*100,2)))\n",
    "    print(textpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text have probabilities of being toxic(99.98%), severe toxic(37.65%), obscene(99.96%), threat(0.69%), insult(99.94%), and identity hate(3.96%)\n",
      "In conclusion, we predict that this text is a TOXIC text that contains toxic, obscene, and insult contents\n"
     ]
    }
   ],
   "source": [
    "text = 'you are asshole'\n",
    "predict_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>toxic_level</th>\n",
       "      <th>clean</th>\n",
       "      <th>length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>264</td>\n",
       "      <td>43</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>18</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>233</td>\n",
       "      <td>42</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.406667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\" More I can't make any real suggestions on im...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>622</td>\n",
       "      <td>116</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.301042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation Why the edits made under my userna...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \" More I can't make any real suggestions on im...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  toxic_level  clean  \\\n",
       "0             0        0       0       0              0            0      1   \n",
       "1             0        0       0       0              0            0      1   \n",
       "2             0        0       0       0              0            0      1   \n",
       "3             0        0       0       0              0            0      1   \n",
       "4             0        0       0       0              0            0      1   \n",
       "\n",
       "   length  word_count  polarity  subjectivity  \n",
       "0     264          43  0.136364      0.454545  \n",
       "1     112          18  0.287500      0.550000  \n",
       "2     233          42  0.160000      0.406667  \n",
       "3     622         116  0.200000      0.301042  \n",
       "4      67          13  0.000000      0.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
